{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "A)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7e99ef306915194"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numarul de propozitii: 10\n",
      "Propoziția 1: Mesaj de informare:\n",
      "Cursul și laboratoarele de Inteligență Artificială vor fi o\n",
      "provocare pentru toți.\n",
      "Propoziția 2: Suntem convinși că veți realiza proiecte\n",
      "foarte interesante.\n",
      "Propoziția 3: Vă încurajăm să adresați întrebări atunci\n",
      "când ceva nu e clar, atât în mod live, cât și folosind platforma\n",
      "Teams, canalul ”general”.\n",
      "Propoziția 4: Dacă ați citit până aici, vă rugăm să lăsați un mesaj pe canalul\n",
      "general cu textul ”Confiiiiiiiiiiiiiiiiiiiiiiiiiiiirm că am citit\n",
      "textul pentru problema 3 din lab2”.\n",
      "Propoziția 5: --\n",
      "Mesaj de informare generat de ChatGPT:\n",
      "Stimați cursanți,\n",
      "Suntem încântați să vă avem în echipa noastră pentru Cursul și\n",
      "laboratoarele de Inteligență Artificială.\n",
      "Propoziția 6: Această experiență va\n",
      "fi o adevărată provocare, dar suntem convinși că veți realiza\n",
      "proiecte extrem de interesante.\n",
      "Propoziția 7: Vă încurajăm să fiți activi și să adresați întrebări atunci când\n",
      "ceva nu este clar.\n",
      "Propoziția 8: Fie că este vorba de o discuție în timp real\n",
      "sau prin intermediul platformei Teams, canalul ”general”, suntem\n",
      "aici să vă sprijinim.\n",
      "Propoziția 9: Succes și să înceapă aventura AI!\n",
      "Propoziția 10: Cu considerație, Echipa de Inteligență Artificială\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "\n",
    "with open('text.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "print(f\"Numarul de propozitii: {len(sentences)}\")\n",
    "for i, sentence in enumerate(sentences, 1):\n",
    "    print(f\"Propoziția {i}: {sentence}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-12T16:51:15.909404100Z",
     "start_time": "2025-03-12T16:51:08.976839800Z"
    }
   },
   "id": "c75ad4a0454f2d62"
  },
  {
   "cell_type": "markdown",
   "source": [
    "B)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6632251a616a885a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numarul de cuvinte: 160\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "with open('text.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "   \n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "filtered_words = []\n",
    "for word in words:\n",
    "    if word.isalnum():\n",
    "        filtered_words.append(word)\n",
    "\n",
    "print(f\"Numarul de cuvinte: {len(filtered_words)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-12T16:51:15.926971200Z",
     "start_time": "2025-03-12T16:51:15.909404100Z"
    }
   },
   "id": "d70febaa0b669366"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numarul de cuvinte: 160\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "with open('text.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "filtered_words = []\n",
    "for word in words:\n",
    "    if re.search('[a-z 0-9 A-ZăâîșțĂÂÎȘȚ]', word):\n",
    "        filtered_words.append(word)\n",
    "\n",
    "print(f\"Numarul de cuvinte: {len(filtered_words)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-12T20:14:51.198218200Z",
     "start_time": "2025-03-12T20:14:51.138214300Z"
    }
   },
   "id": "630f6e25a96f4b63"
  },
  {
   "cell_type": "markdown",
   "source": [
    "C)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a3d9710dc8abea8"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a94d86eb41fa1fe"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numarul de cuvinte unice: 92\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "with open('text.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "unique_words = set()\n",
    "for word in words:\n",
    "    if re.search('[a-z0-9A-ZăâîșțĂÂÎȘȚ]', word):\n",
    "        unique_words.add(word.lower())\n",
    "\n",
    "print(f\"Numarul de cuvinte unice: {len(unique_words)}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-12T16:51:16.029130900Z",
     "start_time": "2025-03-12T16:51:15.948283300Z"
    }
   },
   "id": "4f75f0845f71d87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "D)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87f3876ef2ea598a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cel mai lung cuvant: Confiiiiiiiiiiiiiiiiiiiiiiiiiiiirm\n",
      "Cele mai scurte cuvinte: ['3', 'e', 'o']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "with open('text.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "unique_words = set()\n",
    "for word in words:\n",
    "    if re.search('[a-z0-9A-ZăâîșțĂÂÎȘȚ]', word):\n",
    "        unique_words.add(word.lower())\n",
    "\n",
    "shortest = []\n",
    "for word in unique_words:\n",
    "    if len(word) == 1:\n",
    "        shortest.append(word)\n",
    "\n",
    "longest = max(filtered_words, key=len)\n",
    "print(f\"Cel mai lung cuvant: {longest}\")\n",
    "print(f\"Cele mai scurte cuvinte: {shortest}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-12T16:51:16.029130900Z",
     "start_time": "2025-03-12T16:51:15.979589200Z"
    }
   },
   "id": "859bce9376893954"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesaj de informare:\n",
      "Cursul si laboratoarele de Inteligenta Artificiala vor fi o\n",
      "provocare pentru toti. Suntem convinsi ca veti realiza proiecte\n",
      "foarte interesante. Va incurajam sa adresati intrebari atunci\n",
      "cand ceva nu e clar, atat in mod live, cat si folosind platforma\n",
      "Teams, canalul ”general”.\n",
      "Daca ati citit pana aici, va rugam sa lasati un mesaj pe canalul\n",
      "general cu textul ”Confiiiiiiiiiiiiiiiiiiiiiiiiiiiirm ca am citit\n",
      "textul pentru problema 3 din lab2”.\n",
      "--\n",
      "Mesaj de informare generat de ChatGPT:\n",
      "Stimati cursanti,\n",
      "Suntem incantati sa va avem in echipa noastra pentru Cursul si\n",
      "laboratoarele de Inteligenta Artificiala. Aceasta experienta va\n",
      "fi o adevarata provocare, dar suntem convinsi ca veti realiza\n",
      "proiecte extrem de interesante.\n",
      "Va incurajam sa fiti activi si sa adresati intrebari atunci cand\n",
      "ceva nu este clar. Fie ca este vorba de o discutie in timp real\n",
      "sau prin intermediul platformei Teams, canalul ”general”, suntem\n",
      "aici sa va sprijinim.\n",
      "Succes si sa inceapa aventura AI!\n",
      "Cu consideratie, Echipa de Inteligenta Artificiala\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "\n",
    "def remove_d(txt):\n",
    "    norm_form = unicodedata.normalize('NFD', txt)\n",
    "    result = \"\"\n",
    "\n",
    "    for c in norm_form:\n",
    "        if not unicodedata.combining(c):\n",
    "            result += c\n",
    "    return result\n",
    "\n",
    "\n",
    "with open('text.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "    norm_text = remove_d(text)\n",
    "print(norm_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-12T17:08:46.708233600Z",
     "start_time": "2025-03-12T17:08:46.671523500Z"
    }
   },
   "id": "68fa169d25bfb2e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "E)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3a46ad5f5581d49"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-12T17:11:48.568146500Z",
     "start_time": "2025-03-12T17:11:48.563262Z"
    }
   },
   "id": "88e3cea731a2fb27"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
