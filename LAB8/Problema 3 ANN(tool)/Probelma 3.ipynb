{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-08T08:07:31.232054Z",
     "start_time": "2025-05-08T08:07:29.484293Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "data = pd.read_csv('eco_500_sentences.csv')\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        return text\n",
    "    return ''\n",
    "\n",
    "data['Text'] = data['Text'].apply(clean_text)\n",
    "data = data[data['Text'] != ''].dropna()\n",
    "\n",
    "# vaori binare pentru senitmente\n",
    "data['Sentiment'] = data['Sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# separ datele\n",
    "texts = data['Text'].values\n",
    "labels = data['Sentiment'].values\n",
    "\n",
    "# vectrorizare TD-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(texts).toarray()\n",
    "\n",
    "# impart datele in ytrain si test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# smote pentru a balansa clasele\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# antrenarea si construirea retelei cu un layer\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(32, ),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=180,\n",
    "    random_state=42\n",
    ")\n",
    "mlp.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# acuratetea\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(f\"Acuratețea pe setul de test: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nMatrice de confuzie:\")\n",
    "print(\"                    Predicție Negativ (0)  Predicție Pozitiv (1)\")\n",
    "print(f\"Adevărat Negativ (0)      {cm[0,0]:<20} {cm[0,1]:<20}\")\n",
    "print(f\"Adevărat Pozitiv (1)      {cm[1,0]:<20} {cm[1,1]:<20}\")\n",
    "print(\"\\nExplicație:\")\n",
    "print(f\"True Negative (TN): {cm[0,0]} - Corect clasificate ca negativ\")\n",
    "print(f\"False Positive (FP): {cm[0,1]} - Incorect clasificate ca pozitiv\")\n",
    "print(f\"False Negative (FN): {cm[1,0]} - Incorect clasificate ca negativ\")\n",
    "print(f\"True Positive (TP): {cm[1,1]} - Corect clasificate ca pozitiv\")\n",
    "\n",
    "# mesajul pentru care aplic modleul\n",
    "message = \"By choosing a bike over a car, I’m reducing my environmental footprint. Cycling promotes eco-friendly transportation, and I’m proud to be part of that movement.\"\n",
    "message_cleaned = clean_text(message)\n",
    "message_vectorized = vectorizer.transform([message_cleaned]).toarray()\n",
    "\n",
    "# preidictia\n",
    "prediction = mlp.predict(message_vectorized)[0]\n",
    "sentiment = 'pozitiv' if prediction == 1 else 'negativ'\n",
    "print(f\"Sentimentul mesajului este: {sentiment}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratețea pe setul de test: 1.00\n",
      "\n",
      "Matrice de confuzie:\n",
      "                    Predicție Negativ (0)  Predicție Pozitiv (1)\n",
      "Adevărat Negativ (0)      52                   0                   \n",
      "Adevărat Pozitiv (1)      0                    48                  \n",
      "\n",
      "Explicație:\n",
      "True Negative (TN): 52 - Corect clasificate ca negativ\n",
      "False Positive (FP): 0 - Incorect clasificate ca pozitiv\n",
      "False Negative (FN): 0 - Incorect clasificate ca negativ\n",
      "True Positive (TP): 48 - Corect clasificate ca pozitiv\n",
      "Sentimentul mesajului este: pozitiv\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T08:07:49.502308Z",
     "start_time": "2025-05-08T08:07:45.988187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "data = pd.read_csv('reviews_mixed.csv')\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        return text\n",
    "    return ''\n",
    "\n",
    "data['Text'] = data['Text'].apply(clean_text)\n",
    "data = data[data['Text'] != ''].dropna()\n",
    "\n",
    "# vaori binare pentru senitmente\n",
    "data['Sentiment'] = data['Sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# separ datele\n",
    "texts = data['Text'].values\n",
    "labels = data['Sentiment'].values\n",
    "\n",
    "# vectrorizare TD-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(texts).toarray()\n",
    "\n",
    "# impart datele in ytrain si test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# smote pentru a balansa clasele\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# antrenarea si construirea retelei cu un layer\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(32,),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "mlp.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# acuratetea\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(f\"Acuratețea pe setul de test: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nMatrice de confuzie:\")\n",
    "print(\"                    Predicție Negativ (0)  Predicție Pozitiv (1)\")\n",
    "print(f\"Adevărat Negativ (0)      {cm[0,0]:<20} {cm[0,1]:<20}\")\n",
    "print(f\"Adevărat Pozitiv (1)      {cm[1,0]:<20} {cm[1,1]:<20}\")\n",
    "print(\"\\nExplicație:\")\n",
    "print(f\"True Negative (TN): {cm[0,0]} - Corect clasificate ca negativ\")\n",
    "print(f\"False Positive (FP): {cm[0,1]} - Incorect clasificate ca pozitiv\")\n",
    "print(f\"False Negative (FN): {cm[1,0]} - Incorect clasificate ca negativ\")\n",
    "print(f\"True Positive (TP): {cm[1,1]} - Corect clasificate ca pozitiv\")\n",
    "\n",
    "# mesajul pentru care aplic modleul\n",
    "message = \"By choosing a bike over a car, I’m reducing my environmental footprint. Cycling promotes eco-friendly transportation, and I’m proud to be part of that movement.\"\n",
    "message_cleaned = clean_text(message)\n",
    "message_vectorized = vectorizer.transform([message_cleaned]).toarray()\n",
    "\n",
    "# preidictia\n",
    "prediction = mlp.predict(message_vectorized)[0]\n",
    "sentiment = 'pozitiv' if prediction == 1 else 'negativ'\n",
    "print(f\"Sentimentul mesajului este: {sentiment}\")"
   ],
   "id": "26db130423675a19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratețea pe setul de test: 0.86\n",
      "\n",
      "Matrice de confuzie:\n",
      "                    Predicție Negativ (0)  Predicție Pozitiv (1)\n",
      "Adevărat Negativ (0)      28                   2                   \n",
      "Adevărat Pozitiv (1)      4                    8                   \n",
      "\n",
      "Explicație:\n",
      "True Negative (TN): 28 - Corect clasificate ca negativ\n",
      "False Positive (FP): 2 - Incorect clasificate ca pozitiv\n",
      "False Negative (FN): 4 - Incorect clasificate ca negativ\n",
      "True Positive (TP): 8 - Corect clasificate ca pozitiv\n",
      "Sentimentul mesajului este: negativ\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "da45e7f39163168c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "14d3ad5d515c4daf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "99a77ed37a4d56c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T18:17:03.928772Z",
     "start_time": "2025-05-07T18:16:58.295710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import re\n",
    "\n",
    "\n",
    "data = pd.read_csv('reviews_mixed.csv')\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        return text\n",
    "    return ''\n",
    "\n",
    "data['Text'] = data['Text'].apply(clean_text)\n",
    "data = data[data['Text'] != ''].dropna()\n",
    "\n",
    "data['Sentiment'] = data['Sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "texts = data['Text'].values\n",
    "labels = data['Sentiment'].values\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(texts).toarray()\n",
    "\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(f\"Număr de termeni în vocabular: {len(vocab)}\")\n",
    "key_terms = ['eco', 'friendly', 'proud', 'environmental', 'cycling', 'footprint']\n",
    "for term in key_terms:\n",
    "    if term in vocab:\n",
    "        print(f\"Termenul '{term}' este în vocabular.\")\n",
    "    else:\n",
    "        print(f\"Termenul '{term}' NU este în vocabular.\")\n",
    "\n",
    "# Împărțim datele\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(32, ),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=1000,\n",
    "    alpha=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "mlp.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(f\"Acuratețea pe setul de test: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "message = \"By choosing a bike over a car, I’m reducing my environmental footprint. Cycling promotes eco-friendly transportation, and I’m proud to be part of that movement.\"\n",
    "message_cleaned = clean_text(message)\n",
    "message_vectorized = vectorizer.transform([message_cleaned]).toarray()\n",
    "\n",
    "prediction = mlp.predict(message_vectorized)[0]\n",
    "sentiment = 'pozitiv' if prediction == 1 else 'negativ'\n",
    "print(f\"Sentimentul mesajului este: {sentiment}\")\n",
    "\n",
    "message_terms = vectorizer.inverse_transform(message_vectorized)[0]\n",
    "print(f\"Termeni din mesaj capturați de TF-IDF: {message_terms}\")"
   ],
   "id": "a9ab2446acd374b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versiune scikit-learn: 1.6.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Număr de termeni în vocabular: 1293\n",
      "Termenul 'eco' NU este în vocabular.\n",
      "Termenul 'friendly' NU este în vocabular.\n",
      "Termenul 'proud' NU este în vocabular.\n",
      "Termenul 'environmental' NU este în vocabular.\n",
      "Termenul 'cycling' NU este în vocabular.\n",
      "Termenul 'footprint' NU este în vocabular.\n",
      "Acuratețea pe setul de test: 0.79\n",
      "Sentimentul mesajului este: negativ\n",
      "Termeni din mesaj capturați de TF-IDF: []\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
